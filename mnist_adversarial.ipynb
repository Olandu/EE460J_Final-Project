{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import network.network as Network\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(\"train\", \"rb\")\n",
    "training_data = np.load(infile, encoding='latin1')\n",
    "infile.close()\n",
    "\n",
    "infile2 = open(\"test\", \"rb\")\n",
    "test_data = np.load(infile2, encoding='latin1')\n",
    "infile2.close()\n",
    "\n",
    "with open('network/trained_network.pkl', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    net = u.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "                                                                                                                                                                                \n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def input_derivative(net, x, y):\n",
    "    \"\"\" Calculate derivatives wrt the inputs\"\"\"\n",
    "    nabla_b = [np.zeros(b.shape) for b in net.biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in net.weights]\n",
    "    \n",
    "    # feedforward\n",
    "    activation = x\n",
    "    activations = [x] # list to store all the activations, layer by layer\n",
    "    zs = [] # list to store all the z vectors, layer by layer\n",
    "    for b, w in zip(net.biases, net.weights):\n",
    "        z = np.dot(w, activation)+b\n",
    "        zs.append(z)\n",
    "        activation = sigmoid(z)\n",
    "        activations.append(activation)\n",
    "        \n",
    "    # backward pass\n",
    "    delta = net.cost_derivative(activations[-1], y) * \\\n",
    "        sigmoid_prime(zs[-1])\n",
    "    nabla_b[-1] = delta\n",
    "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "    for l in range(2, net.num_layers):\n",
    "        z = zs[-l]\n",
    "        sp = sigmoid_prime(z)\n",
    "        delta = np.dot(net.weights[-l+1].transpose(), delta) * sp\n",
    "        nabla_b[-l] = delta\n",
    "        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        \n",
    "    # Return derivatives WRT to input\n",
    "    return net.weights[0].T.dot(delta)\n",
    "\n",
    "def adversarial(net, n, steps, eta):\n",
    "    \"\"\"\n",
    "    net : network object\n",
    "        neural network instance to use\n",
    "    n : integer\n",
    "        our goal label (just an int, the function transforms it into a one-hot vector)\n",
    "    steps : integer\n",
    "        number of steps for gradient descent\n",
    "    eta : float\n",
    "        step size for gradient descent\n",
    "    \"\"\"\n",
    "    # Set the goal output\n",
    "    goal = np.zeros((10, 1))\n",
    "    goal[n] = 1\n",
    "\n",
    "    # Create a random image to initialize gradient descent with\n",
    "    x = np.random.normal(.5, .3, (784, 1))\n",
    "\n",
    "    # Gradient descent on the input\n",
    "    for i in range(steps):\n",
    "        # Calculate the derivative\n",
    "        d = input_derivative(net,x,goal)\n",
    "        \n",
    "        # The GD update on x\n",
    "        x -= eta * d\n",
    "        \n",
    "    return x\n",
    "\n",
    "# Wrapper function\n",
    "def generate(n):\n",
    "    \"\"\"\n",
    "    n : integer\n",
    "        goal label (not a one hot vector)\n",
    "    \"\"\"\n",
    "    # a = adversarial(net, n, 1000, 1)\n",
    "    a = adversarial(net, n, 1000, 0.15)\n",
    "    x = np.round(net.feedforward(a), 2)\n",
    "    \n",
    "    print('Network Output: \\n' + str(x) + '\\n')\n",
    "    \n",
    "    print('Network Prediction: ' + str(np.argmax(x)) + '\\n')\n",
    "    \n",
    "    print('Adversarial Example: ')\n",
    "    plt.imshow(a.reshape(28,28), cmap='Greys')\n",
    "    \n",
    "def sneaky_adversarial(net, n, x_target, steps, eta, lam=.05):\n",
    "    \"\"\"\n",
    "    net : network object\n",
    "        neural network instance to use\n",
    "    n : integer\n",
    "        our goal label (just an int, the function transforms it into a one-hot vector)\n",
    "    x_target : numpy vector\n",
    "        our goal image for the adversarial example\n",
    "    steps : integer\n",
    "        number of steps for gradient descent\n",
    "    eta : float\n",
    "        step size for gradient descent\n",
    "    lam : float\n",
    "        lambda, our regularization parameter. Default is .05\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the goal output\n",
    "    goal = np.zeros((10, 1))\n",
    "    goal[n] = 1\n",
    "\n",
    "    # Create a random image to initialize gradient descent with\n",
    "    # x = np.random.normal(.5, .3, (784, 1))\n",
    "    \n",
    "    # Initialize noise to 0\n",
    "    noise = np.zeros((784, 1), dtype=float)\n",
    "\n",
    "    # Gradient descent on the input\n",
    "    for i in range(steps):\n",
    "        print(\"Iteration: \", i)\n",
    "        \n",
    "        noisy_image = x_target + noise\n",
    "        noisy_image = np.clip(a=noisy_image, a_min=0.0, a_max=1.0)\n",
    "        \n",
    "        # Do the prediction\n",
    "        pred = net.feedforward(noisy_image)\n",
    "        score_target = pred[n]\n",
    "        \n",
    "        # Calculate the derivative\n",
    "        grad = input_derivative(net,noisy_image,goal)\n",
    "        sq_grad = np.array(grad).squeeze()\n",
    "        grad_absmax = np.abs(grad).max()\n",
    "        \n",
    "        # If the gradient is very small then use a lower limit,\n",
    "        # because we will use it as a divisor.\n",
    "        if grad_absmax < 1e-10:\n",
    "            grad_absmax = 1e-10\n",
    "            \n",
    "        # Calculate the step-size for updating the image-noise.\n",
    "        # This ensures that at least one pixel colour is changed by 7.\n",
    "        # Recall that pixel colours can have 255 different values.\n",
    "        # This step-size was found to give fast convergence.\n",
    "        step_size = 0.01 / grad_absmax\n",
    "        \n",
    "        # The GD update on x, with an added penalty to the cost function\n",
    "        # ONLY CHANGE IS RIGHT HERE!!!\n",
    "        # x -= eta * (grad + lam * (x - x_target))\n",
    "        \n",
    "        if score_target < 0.5:\n",
    "            # Update the image-noise by subtracting the gradient\n",
    "            # scaled by the step-size.\n",
    "            noise -= step_size * grad\n",
    "\n",
    "            # Ensure the noise is within the desired range.\n",
    "            # This avoids distorting the image too much.\n",
    "            noise = np.clip(a=noise,\n",
    "                            a_min=-1.0,\n",
    "                            a_max=1.0)\n",
    "        else:\n",
    "            # Abort the optimization because the score is high enough.\n",
    "            break\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "# Wrapper function\n",
    "def sneaky_generate(n, m):\n",
    "    \"\"\"\n",
    "    n: int 0-9, the target number to match\n",
    "    m: index of example image to use (from the test set)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find random instance of m in test set\n",
    "    idx = np.random.randint(0,8000)\n",
    "    while test_data[idx][1] != m:\n",
    "        idx += 1\n",
    "    \n",
    "    # Hardcode the parameters for the wrapper function\n",
    "    # net, n, x_target, steps, eta, lam=.05\n",
    "    a = sneaky_adversarial(net, n, test_data[idx][0], 1000, 0.1, lam=0.05)\n",
    "    # x = np.round(net.feedforward(a), 2)\n",
    "    x = net.feedforward(a)\n",
    "    \n",
    "    print('\\nWhat we want our adversarial example to look like: ')\n",
    "    plt.imshow(test_data[idx][0].reshape((28,28)), cmap='Greys')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    print('Adversarial Example: ')\n",
    "    \n",
    "    plt.imshow(a.reshape(28,28), cmap='Greys')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Network Prediction: ' + str(np.argmax(x)) + '\\n')\n",
    "    \n",
    "    #print('Network Output: \\n' + str(x) + '\\n')\n",
    "    print(\"Network Output:\")\n",
    "    print(x)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "Iteration:  26\n",
      "Iteration:  27\n",
      "Iteration:  28\n",
      "Iteration:  29\n",
      "Iteration:  30\n",
      "Iteration:  31\n",
      "Iteration:  32\n",
      "Iteration:  33\n",
      "Iteration:  34\n",
      "Iteration:  35\n",
      "Iteration:  36\n",
      "Iteration:  37\n",
      "Iteration:  38\n",
      "Iteration:  39\n",
      "Iteration:  40\n",
      "Iteration:  41\n",
      "Iteration:  42\n",
      "Iteration:  43\n",
      "Iteration:  44\n",
      "Iteration:  45\n",
      "Iteration:  46\n",
      "Iteration:  47\n",
      "Iteration:  48\n",
      "Iteration:  49\n",
      "Iteration:  50\n",
      "Iteration:  51\n",
      "Iteration:  52\n",
      "Iteration:  53\n",
      "Iteration:  54\n",
      "Iteration:  55\n",
      "Iteration:  56\n",
      "Iteration:  57\n",
      "Iteration:  58\n",
      "Iteration:  59\n",
      "\n",
      "What we want our adversarial example to look like: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Adversarial Example: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Prediction: 1\n",
      "\n",
      "Network Output:\n",
      "[[5.59463958e-12]\n",
      " [5.34999986e-01]\n",
      " [9.28487650e-04]\n",
      " [1.70683425e-04]\n",
      " [4.49291224e-09]\n",
      " [6.24584055e-06]\n",
      " [4.19229838e-03]\n",
      " [1.90168571e-16]\n",
      " [8.41204835e-09]\n",
      " [2.03746317e-13]]\n"
     ]
    }
   ],
   "source": [
    "adv_ex = sneaky_generate(1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "test_data[idx][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Prediction:  7\n",
      "[[3.84940104e-10]\n",
      " [3.09685480e-09]\n",
      " [2.71110833e-06]\n",
      " [2.50655822e-09]\n",
      " [7.76256740e-08]\n",
      " [5.71491074e-06]\n",
      " [1.28826623e-05]\n",
      " [7.98682411e-05]\n",
      " [5.99688781e-05]\n",
      " [1.84192658e-05]]\n"
     ]
    }
   ],
   "source": [
    "pred = net.feedforward(adv_ex)\n",
    "print(\"Network Prediction: \", str(np.argmax(pred)))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
